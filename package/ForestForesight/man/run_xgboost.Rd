% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_xgboost.R
\name{run_xgboost}
\alias{run_xgboost}
\alias{train_xgboost}
\title{Train an XGBoost Model}
\usage{
train_xgboost(
  train_matrix,
  validation_matrix = NA,
  nrounds = 200,
  eta = 0.1,
  max_depth = 5,
  subsample = 0.75,
  eval_metric = "aucpr",
  early_stopping_rounds = 10,
  verbose = F
)
}
\arguments{
\item{train_matrix}{The training matrix for XGBoost. should be of type xgb.Dmatrix}

\item{validation_matrix}{The matrix to run for the model for XGBoost. should be of type xgb.Dmatrix}

\item{nrounds}{Number of boosting rounds. Default is 200.}

\item{eta}{Learning rate. Default is 0.1.}

\item{max_depth}{Maximum tree depth. Default is 5.}

\item{subsample}{Subsample ratio of the training instances. Default is 0.75.}

\item{eval_metric}{Evaluation metric. Default is "aucpr".}

\item{early_stopping_rounds}{Early stopping rounds. Default is 10.}

\item{verbose}{should the model run verbose. Default is FALSE.}
}
\value{
Trained XGBoost model.
}
\description{
This function trains an XGBoost model with default parameters.
}
\examples{
# Example usage:
train_matrix <- matrix(c(1, 2, 3, 4), ncol = 2)
model <- train_xgboost(train_matrix)

}
\references{
Jonas van Duijvenbode (2023)
}
\keyword{XGBoost}
\keyword{data}
\keyword{preparation}
